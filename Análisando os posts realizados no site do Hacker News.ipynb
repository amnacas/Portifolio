{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Análisando os posts realizados no site do Hacker News\n",
    "\n",
    "\n",
    "## Descrição do projeto\n",
    "\n",
    "O Hacker News é um site que criado pela incubadora de startups Y Combinator, onde os usuários realizam postagens que podem ser comentadas e votadas, de forma semelhante ao reddit. Esse site é bastante popular na área de tecnologia e startups, em geral as postagens que estão no too das listagens do Hackers News rebem centenas de milhares de vizualizações.\n",
    "\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Neste projeto, compararemos dois tipos diferentes de postagens do Hacker News. Os dois tipos de postagens que exploraremos começam com *Ask HN* ou *Show HN*.\n",
    "\n",
    "Os usuários enviam as postagens com *Ask HN* para fazer uma pergunta específica à comunidade Hacker News, como \"Qual é o melhor curso online que você já fez?\" Da mesma forma, os usuários enviam postagens com *Show HN* para mostrar à comunidade Hacker News um projeto, produto ou simplesmente algo interessante.\n",
    "\n",
    "Compararemos especificamente esses dois tipos de postagens para determinar o seguinte:\n",
    "\n",
    "* O *Ask HN* ou *Show HN* recebe mais comentários em média?\n",
    "* As postagens criadas em um determinado momento recebem, em média, mais comentários?\n",
    "\n",
    "\n",
    "## Dados\n",
    "\n",
    "O conjunto de dados utilizado nesse projeto está disponível no  [Kaggle](https://www.kaggle.com/hacker-news/hacker-news-posts), mas observe que ele foi reduzido de quase 300.000 linhas para aproximadamente 20.000 linhas, removendo todos os envios que não receberam nenhum comentário e, em seguida, amostrando aleatóriamente os envios restantes. \n",
    "\n",
    "\n",
    "## Dicionário de Variáveis \n",
    "\n",
    "O arquivo \"hacker_news.csv\" importado possui 20101 linhas e 7 colunas correspondentes as variáveis listadas a seguir:\n",
    "\n",
    "**Listagem e descrição das variáveis**:\n",
    "\n",
    "* *id*: O identificador exclusivo do Hacker News para a postagem.\n",
    "* *title*: O título do post\n",
    "* *url*: O URL para o qual as postagens estão vinculadas, se a postagem tiver um URL\n",
    "* *num_points*: Número de pontos que a postagem conseguiu, calculado como o total de votos positivos menos o total de votos negativos.\n",
    "* *num_comments*: Número de comentários feitos no post.\n",
    "* *author*: O nick do usuário que submeteu o post.\n",
    "* *created_at*: A data e o horário que o post foi submetido.\n",
    "\n",
    "\n",
    "## Preparação e limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "### The Hackers News dataset ###\n",
    "opened_file = open('hacker_news.csv', encoding=\"utf8\")\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') \n",
    "        \n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "\n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "\n",
      "\n",
      "Number of rows: 20101\n",
      "Number of columns: 7\n"
     ]
    }
   ],
   "source": [
    "explore_data(hn,0,5,rows_and_columns=True)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20'],\n",
       " ['11919867',\n",
       "  'Technology ventures: From Idea to Enterprise',\n",
       "  'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
       "  '3',\n",
       "  '1',\n",
       "  'hswarna',\n",
       "  '6/17/2016 0:01'],\n",
       " ['10301696',\n",
       "  'Note by Note: The Making of Steinway L1037 (2007)',\n",
       "  'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0',\n",
       "  '8',\n",
       "  '2',\n",
       "  'walterbell',\n",
       "  '9/30/2015 4:12'],\n",
       " ['10482257',\n",
       "  'Title II kills investment? Comcast and other ISPs are now spending more',\n",
       "  'http://arstechnica.com/business/2015/10/comcast-and-other-isps-boost-network-investment-despite-net-neutrality/',\n",
       "  '53',\n",
       "  '22',\n",
       "  'Deinos',\n",
       "  '10/31/2015 9:48']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separando o header e os dados\n",
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "hn[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como temos como objetivo analisar as postagens com *Ask HN* e *Show HN*, iremos separar os dados nesses dois grupos. Para isso será utilizado o método *startswith*. Esse método funciona da seguinte forma:\n",
    "\n",
    "Dado um objeto string, digamos, **string1**, podemos verificar se começa com, digamos, **Ask HN** inspecionando a saída do objeto **string1.startswith ('Ask HN')**. Se **string1** começar com **Ask HN**, ela retornará **True**, caso contrário, retornará **False**.\n",
    "\n",
    "No entanto, devemos nos atentar que esse método é sensivel a presença de letras maiúsculas e minúsculas. Por isso, iremos utilizar o método *lower* para garantir a identificação correta dos posts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title =  row[1].lower()\n",
    "    if title.startswith(\"ask hn\"):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith(\"show hn\"): \n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55']\n",
      "\n",
      "\n",
      "Number of rows: 1744\n",
      "Number of columns: 7\n"
     ]
    }
   ],
   "source": [
    "explore_data(ask_posts,0,1,rows_and_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03']\n",
      "\n",
      "\n",
      "Number of rows: 1162\n",
      "Number of columns: 7\n"
     ]
    }
   ],
   "source": [
    "explore_data(show_posts,0,1,rows_and_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "Number of rows: 17193\n",
      "Number of columns: 7\n"
     ]
    }
   ],
   "source": [
    "explore_data(other_posts,0,1,rows_and_columns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo sido separados os posts nos grupos *Ask HN* e *Show HN*, agora iremos verificar o número total de comentários e a média de comentários por post do tipo *Ask HN* e *Show HN*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média de comentários do Ask HN:  14.038417431192661\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments = total_ask_comments + num_comments\n",
    "    \n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)    \n",
    "print(\"Média de comentários do Ask HN: \", avg_ask_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média de comentários do Show HN:  10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments = total_show_comments + num_comments\n",
    "    \n",
    "avg_show_comments = total_show_comments/len(show_posts)    \n",
    "print(\"Média de comentários do Show HN: \", avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em média, as postagens de perguntas (*Ask HN*) em nossa amostra recebem aproximadamente 14 comentários, enquanto as postagens do tipo *Show HN* recebem aproximadamente 10. \n",
    "\n",
    "Como as postagens de perguntas (*Ask HN*) apresentam uma maior probabilidade de receber comentários, concentraremos nossa análise restante apenas nessas postagens. \n",
    "\n",
    "Agora será avaliado se os posts criados em um determinado momento tem maior chance de atrair comentários. Para isso seguiremos os seguintes passos:\n",
    "\n",
    "* Calcular a quantidade de posts do tipo *Ask HN* por hora do dia e a quantidade de de comentários recebidos.\n",
    "* Calcular o número médio de comentários nos posts do tipo *Ask HN* por hora.\n",
    "\n",
    "Para isso iremos utilizar o módulo **datetime** para trabalhar com os dados da coluna *created_at*:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'09': 251,\n",
       " '13': 1253,\n",
       " '10': 793,\n",
       " '14': 1416,\n",
       " '16': 1814,\n",
       " '23': 543,\n",
       " '12': 687,\n",
       " '17': 1146,\n",
       " '15': 4477,\n",
       " '21': 1745,\n",
       " '20': 1722,\n",
       " '02': 1381,\n",
       " '18': 1439,\n",
       " '03': 421,\n",
       " '05': 464,\n",
       " '19': 1188,\n",
       " '01': 683,\n",
       " '22': 479,\n",
       " '08': 492,\n",
       " '04': 337,\n",
       " '00': 447,\n",
       " '06': 397,\n",
       " '07': 267,\n",
       " '11': 641}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculando o número de comentários por hora\n",
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "for row in ask_posts:\n",
    "    created_at = row[6]\n",
    "    num_comments = int(row[4])\n",
    "    result_list.append([created_at, num_comments])\n",
    "    \n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "date_format = \"%m/%d/%Y %H:%M\"\n",
    "\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    comment = row[1]\n",
    "    time = dt.datetime.strptime(date, date_format).strftime(\"%H\")\n",
    "    if time in counts_by_hour:\n",
    "        comments_by_hour[time] += comment\n",
    "        counts_by_hour[time] += 1\n",
    "    else:\n",
    "        comments_by_hour[time] = comment\n",
    "        counts_by_hour[time] = 1\n",
    "\n",
    "comments_by_hour\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['09', 5.5777777777777775],\n",
       " ['13', 14.741176470588234],\n",
       " ['10', 13.440677966101696],\n",
       " ['14', 13.233644859813085],\n",
       " ['16', 16.796296296296298],\n",
       " ['23', 7.985294117647059],\n",
       " ['12', 9.41095890410959],\n",
       " ['17', 11.46],\n",
       " ['15', 38.5948275862069],\n",
       " ['21', 16.009174311926607],\n",
       " ['20', 21.525],\n",
       " ['02', 23.810344827586206],\n",
       " ['18', 13.20183486238532],\n",
       " ['03', 7.796296296296297],\n",
       " ['05', 10.08695652173913],\n",
       " ['19', 10.8],\n",
       " ['01', 11.383333333333333],\n",
       " ['22', 6.746478873239437],\n",
       " ['08', 10.25],\n",
       " ['04', 7.170212765957447],\n",
       " ['00', 8.127272727272727],\n",
       " ['06', 9.022727272727273],\n",
       " ['07', 7.852941176470588],\n",
       " ['11', 11.051724137931034]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculando o número médio de comentários por hora\n",
    "\n",
    "avg_by_hour = []\n",
    "\n",
    "for time in comments_by_hour:\n",
    "    avg_by_hour.append([time, comments_by_hour[time]/counts_by_hour[time]])\n",
    "    \n",
    "avg_by_hour    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos terminar classificando a lista de listas e imprimindo os cinco valores mais altos em um formato mais fácil de ler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.5777777777777775, '09'], [14.741176470588234, '13'], [13.440677966101696, '10'], [13.233644859813085, '14'], [16.796296296296298, '16'], [7.985294117647059, '23'], [9.41095890410959, '12'], [11.46, '17'], [38.5948275862069, '15'], [16.009174311926607, '21'], [21.525, '20'], [23.810344827586206, '02'], [13.20183486238532, '18'], [7.796296296296297, '03'], [10.08695652173913, '05'], [10.8, '19'], [11.383333333333333, '01'], [6.746478873239437, '22'], [10.25, '08'], [7.170212765957447, '04'], [8.127272727272727, '00'], [9.022727272727273, '06'], [7.852941176470588, '07'], [11.051724137931034, '11']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[38.5948275862069, '15'],\n",
       " [23.810344827586206, '02'],\n",
       " [21.525, '20'],\n",
       " [16.796296296296298, '16'],\n",
       " [16.009174311926607, '21'],\n",
       " [14.741176470588234, '13'],\n",
       " [13.440677966101696, '10'],\n",
       " [13.233644859813085, '14'],\n",
       " [13.20183486238532, '18'],\n",
       " [11.46, '17'],\n",
       " [11.383333333333333, '01'],\n",
       " [11.051724137931034, '11'],\n",
       " [10.8, '19'],\n",
       " [10.25, '08'],\n",
       " [10.08695652173913, '05'],\n",
       " [9.41095890410959, '12'],\n",
       " [9.022727272727273, '06'],\n",
       " [8.127272727272727, '00'],\n",
       " [7.985294117647059, '23'],\n",
       " [7.852941176470588, '07'],\n",
       " [7.796296296296297, '03'],\n",
       " [7.170212765957447, '04'],\n",
       " [6.746478873239437, '22'],\n",
       " [5.5777777777777775, '09']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "    \n",
    "print(swap_avg_by_hour)\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "sorted_swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 horários com maior número de comentários para os posts *Ask HN*\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 horários com maior número de comentários para os posts *Ask HN*\")\n",
    "\n",
    "for avg, hr in sorted_swap[:5]:\n",
    "    print( \"{}: {:.2f} average comments per post\".format(\n",
    "            dt.datetime.strptime(hr, \"%H\").strftime(\"%H:%M\"),avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A hora que recebe mais comentários por postagem em média é 15h, com uma média de 38,59 comentários por postagem. Há um aumento de cerca de 60% no número de comentários entre as horas com o maior e o segundo maior número médio de comentários.\n",
    "\n",
    "No entanto, de acordo com a documentação do conjunto de dados, o fuso horário usado é o horário do leste dos EUA.\n",
    "\n",
    "Portanto, aqui no Brasil o melhor momento para publicação de um post no Hackers News seria as 17:00 com o fuso horário de Brasilia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Conclusão \n",
    " \n",
    "Neste projeto, analisamos postagens de perguntas (*Ask HN*) e postagens de exibição (*Show HN*) para determinar que tipo de postagem e horário recebem mais comentários em média.\n",
    "\n",
    "Com base em nossa análise, para maximizar a quantidade de comentários que uma postagem recebe, recomendamos que a postagem seja categorizada como *ask post* e criada entre 17h00 e 18h00 (fuso horário de Brasilia).\n",
    "\n",
    "No entanto, deve-se notar que o conjunto de dados que analisamos excluiu postagens sem quaisquer comentários. Sendo assim, é mais correto dizer que das postagens que receberam comentários, as postagens de perguntas receberam mais comentários em média e as postagens de perguntas criadas entre 17h e 18h (fuso horário de Brasilia) receberam o a maioria dos comentários, em média. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
